{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11364870,"sourceType":"datasetVersion","datasetId":7113544}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Generative AI Kitchen Assistant\n\n## ğŸ§  Problem: What should I cook with what I have?\n\nIt's a common daily dilemma â€” staring at your pantry or fridge, trying to decide what to make. Traditional recipe websites need structured input or specific dish names, but real people often think the following when trying to look for what to make next:\n\n- \"I want to bake something sweet\"\n- \"I have tomatoes, spinach, and eggs â€” what can I cook?\"\n- \"Give me a quick vegan dinner\"\n\nThe problem: natural language is messy. Recipes are messy too. We need something smarter.\n\n#### Home cooks often struggle to find recipes that align with their available ingredients, dietary restrictions, and culinary preferences. This project aims to simplify meal planning by leveraging generative AI to suggest personalized recipes based on user inputs.\n\n### ğŸ¤– Enter Generative AI\n\nThis notebook shows how GenAI can bridge the gap between how people talk and structured data like recipes â€” extracting preferences from natural language and recommending dishes intelligently, even when data is incomplete or vague.\n\n\n### This notebook is part of the submission for the Kaggle & Google 5-day Generative AI course\n\nMy main idea for this project is to have a chat where essentially the AI functions to suggest recipes based on the ingredients a user has and/or what kind of food they prefer to eat. \n\nThe main areas of Generative AI that I learned during the 5-day course and will be included in this project are\n1. Structured output/JSON mode/controlled generation\n2. Few-shot prompting\n3. Retrieval augmented generation (RAG)\n4. Vector search/vector store/vector database\n5. Grounding\n6. Embeddings","metadata":{}},{"cell_type":"markdown","source":"---\n## Download and Import packages (google-genai & chromadb)\nFirst step is to download and import the required packages\n- genai for the Gemini Model\n- Markdown used for displaying output from the model\n- pandas to read in the dataset of recipes\n- json for the structured output\n- chromadb to store embeddings of the recipes","metadata":{}},{"cell_type":"code","source":"!pip uninstall -qqy jupyterlab jupyterlab-lsp # Remove unused conflicting packages\n!pip install -U -q \"google-genai==1.7.0\" \"chromadb==0.6.3\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:24:52.557114Z","iopub.execute_input":"2025-04-20T11:24:52.557336Z","iopub.status.idle":"2025-04-20T11:25:40.772062Z","shell.execute_reply.started":"2025-04-20T11:24:52.557317Z","shell.execute_reply":"2025-04-20T11:25:40.770878Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ----------------------------\n# ğŸ› ï¸ Imports and Setup\n# ----------------------------\nfrom google import genai\nfrom google.genai import types\n\nfrom IPython.display import Markdown\n\ngenai.__version__","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:25:43.575508Z","iopub.execute_input":"2025-04-20T11:25:43.575852Z","iopub.status.idle":"2025-04-20T11:25:45.279304Z","shell.execute_reply.started":"2025-04-20T11:25:43.575820Z","shell.execute_reply":"2025-04-20T11:25:45.278465Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ----------------------------\n# ğŸ› ï¸ Imports and Setup\n# ----------------------------\nimport pandas as pd\nimport ast\nimport json\nimport re\nimport typing_extensions as typing\nfrom typing import Dict, List, Optional","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:25:46.424424Z","iopub.execute_input":"2025-04-20T11:25:46.425485Z","iopub.status.idle":"2025-04-20T11:25:48.756735Z","shell.execute_reply.started":"2025-04-20T11:25:46.425360Z","shell.execute_reply":"2025-04-20T11:25:48.755921Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Set up API key\nTo run the code and access the Gemini models, an API key is required and is accessible at [AI Studio](https://aistudio.google.com/apikey). Add the API key to `Secrets` under `Add-ons` and name it `\"GOOGLE_API_KEY\"`.","metadata":{}},{"cell_type":"code","source":"# ----------------------------\n# ğŸ› ï¸ API Setup\n# ----------------------------\nfrom kaggle_secrets import UserSecretsClient\n\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n\nclient = genai.Client(api_key=GOOGLE_API_KEY)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:25:50.729119Z","iopub.execute_input":"2025-04-20T11:25:50.729648Z","iopub.status.idle":"2025-04-20T11:25:51.324854Z","shell.execute_reply.started":"2025-04-20T11:25:50.729619Z","shell.execute_reply":"2025-04-20T11:25:51.323831Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Creating the embedding database with ChromaDB\n\nCreate a [custom function](https://docs.trychroma.com/guides/embeddings#custom-embedding-functions) to generate embeddings with the Gemini API. This section of code is based on the codelabs provided by Google & Kaggle.\n\nIn the code section, `retrieval_document` generates the document embeddings (the recipes dataset in this case) and `retrieval_query` is used for the query embeddings (a user's request for a recipe).","metadata":{}},{"cell_type":"code","source":"# ----------------------------\n# ğŸ› ï¸ Embedding & ChromaDB Setup\n# ----------------------------\nimport chromadb\nfrom chromadb import Documents, EmbeddingFunction, Embeddings\n\nfrom google.api_core import retry\n\nclass GeminiEmbeddingFunction(EmbeddingFunction):\n    def __init__(self, document_mode=True):\n        self.document_mode = document_mode\n\n    @retry.Retry(predicate=lambda e: isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n    def __call__(self, input: Documents) -> Embeddings:\n        task_type = \"retrieval_document\" if self.document_mode else \"retrieval_query\"\n        response = client.models.embed_content(\n            model=\"models/text-embedding-004\", \n            contents=input,\n            config=types.EmbedContentConfig(task_type=task_type),\n        )\n        return [e.values for e in response.embeddings]\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:25:54.336279Z","iopub.execute_input":"2025-04-20T11:25:54.336887Z","iopub.status.idle":"2025-04-20T11:25:55.209584Z","shell.execute_reply.started":"2025-04-20T11:25:54.336859Z","shell.execute_reply":"2025-04-20T11:25:55.208680Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Load in the dataset\nThe dataset of recipes is taken from [RecipeNLG](https://huggingface.co/datasets/mbien/recipe_nlg): A Cooking Recipes Dataset for Semi-Structured Text Generation.\n\nFor the preprocessing of the dataset, I have decided to remove entries where the recipe name, ingredients, and instructions were `NULL`. Then these values are combined into one column to create a \"document\" for each recipe. ","metadata":{}},{"cell_type":"code","source":"# ----------------------------\n# ğŸ“˜ Load and Filter Recipes\n# ----------------------------\ndf = pd.read_csv('/kaggle/input/recipes/full_dataset.csv')\ndf = df.dropna(subset=['title', 'ingredients', 'directions','NER'])\ndf['full_text'] = df['title'] + ' | ' + df['ingredients'] + ' | ' + df['directions']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:25:57.270778Z","iopub.execute_input":"2025-04-20T11:25:57.271362Z","iopub.status.idle":"2025-04-20T11:27:01.692592Z","shell.execute_reply.started":"2025-04-20T11:25:57.271327Z","shell.execute_reply":"2025-04-20T11:27:01.691586Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Defining the functions\n\nEach function is written to work with the proposed workflow of how I would like the chat to flow and/or behave.\n\n---\n### Extracting user preferences\nThis function works to take in the user's input and then calls on the Gemini model to extract the user's preferences from the input into a JSON format. The prompt that is fed to the model also includes few-shot prompting with a few provided examples on how the model's response should look. \n\n### AI use:\nWith this example of using few-shot prompting and and obtaining a structured output, we're making use of the key NLP characteristics as it interprets user inputs to extract relevant information such as available ingredients, dietary preferences, and desired cuisine types.","metadata":{}},{"cell_type":"code","source":"# ----------------------------\n# ğŸ” Few-Shot Prompt to Extract Preferences\n# ----------------------------\n\n# Create a schema for the ingredients and preferences a person has\n# Preferences can include diet, cuisine, dislikes, etc.\n\nclass Preferences(typing.TypedDict, total=False):\n    ingredients: list[str]\n    diet: str\n    cuisine: str\n    dislikes: list[str]\n    meal_type: str\n    difficulty: str\n    dish: str\n\n\ndef extract_preferences(user_input: str) -> Dict:\n    \"\"\"Function to take in the user's input of preferences and then extract them into a JSON format\"\"\"\n    \n    prompt = f\"\"\"\n    You are a kitchen assistant. Extract structured cooking preferences from user input and return them as JSON.\n    \n    Return these keys:\n    - ingredients (list of strings)\n    - cuisine (string)\n    - diet (string)\n    - dislikes (list of strings)\n    - difficulty (string)\n    - dish (string â€“ if a specific dish is mentioned by the user otherwise keep it empty)\n    \n    If the user says they \"don't have\", \"don't want\", or \"without\" an ingredient, include it in dislikes.\n    And if the user mentions a dietary preference such as \"vegetarian\" and \"pescatarian\", make sure that is stored under\n    \"diet\" and not \"dish\".\n    \n    Use empty strings/lists if something isnâ€™t mentioned.\n    \n    EXAMPLE 1:\n    Input: \"I want to make lasagna\"\n    Output: {{\n      \"ingredients\": [],\n      \"cuisine\": \"\",\n      \"diet\": \"\",\n      \"dislikes\": [],\n      \"difficulty\": \"\",\n      \"dish\": \"lasagna\"\n    }}\n\n    EXAMPLE 2:\n    Input: \"Make me something vegetarian without olives. Something Italian maybe?\"\n    Output: {{\n      \"ingredients\": [],\n      \"cuisine\": \"Italian\",\n      \"diet\": \"vegetarian\",\n      \"dislikes\": [\"olives\"],\n      \"difficulty\": \"\",\n      \"dish\": \"\"\n    }}\n\n    EXAMPLE 3:\n    Input: \"I have tomatoes, pasta, and tuna, but I don't have cheese\"\n    Output: {{\n      \"ingredients\": [\"tomatoes\", \"pasta\", \"tuna\"],\n      \"cuisine\": \"\",\n      \"diet\": \"\",\n      \"dislikes\": [\"cheese\"],\n      \"difficulty\": \"\",\n      \"dish\": \"\"\n    }}\n    \n    USER INPUT:\n    Input: \"{user_input}\"\n    Output:\n    \"\"\"\n    response = client.models.generate_content(\n        model=\"gemini-2.0-flash\",                    # Change the model if JSON not parsed\n        config=types.GenerateContentConfig(\n            temperature=0.1,\n            response_mime_type=\"application/json\",\n            max_output_tokens=512,\n            response_schema=Preferences\n        ),\n        contents=[prompt]\n    )\n    # print(response.text)\n    return json.loads(response.text.strip())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:27:07.108329Z","iopub.execute_input":"2025-04-20T11:27:07.108675Z","iopub.status.idle":"2025-04-20T11:27:07.119887Z","shell.execute_reply.started":"2025-04-20T11:27:07.108651Z","shell.execute_reply":"2025-04-20T11:27:07.119039Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Creating DB of embeddings","metadata":{}},{"cell_type":"code","source":"# ----------------------------\n# ğŸ› ï¸ Embedding & ChromaDB Setup\n# ----------------------------\nchroma_client = chromadb.Client()\n\ndef create_recipe_collection(name=\"recipes\", embedding_fn=None):\n    \"\"\"Creates the chromadb named 'recipes' and applies the embedding function, returns the DB of embeddings\"\"\"\n    existing_collections = chroma_client.list_collections()\n    if name in existing_collections:\n        chroma_client.delete_collection(name)\n    return chroma_client.create_collection(name=name, embedding_function=embedding_fn)\n\n# Initialize embedding function (in document mode for DB creation)\nembed_fn = GeminiEmbeddingFunction(document_mode=True)\ncollection = create_recipe_collection(name=\"recipes\", embedding_fn=embed_fn)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:27:10.226878Z","iopub.execute_input":"2025-04-20T11:27:10.227212Z","iopub.status.idle":"2025-04-20T11:27:10.622793Z","shell.execute_reply.started":"2025-04-20T11:27:10.227175Z","shell.execute_reply":"2025-04-20T11:27:10.621841Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Filtering recipes based on preferences\nI decided to filter the recipes based on the user's preferences before creating embeddings for those recipes to keep API requests limited, considering the fact that the the recipes dataset is large (~2.2 GB)","metadata":{}},{"cell_type":"code","source":"# ----------------------------\n# âœ… Recipe Filtering & Ingestion\n# ----------------------------\ndef filter_and_embed_recipes(prefs: Dict, df: pd.DataFrame) -> Optional[pd.DataFrame]:\n    \"\"\"\n    Filter the recipes based on user preferences and apply the embedding function \n    on the filtered dataset. Returns the filtered DataFrame or None if no matches found.\n    \"\"\"\n    global collection\n    \n    filtered = df.copy()\n\n    # Filter by dish name\n    if prefs.get(\"dish\"):\n        filtered = filtered[filtered['title'].str.contains(prefs[\"dish\"], case=False, na=False)]\n\n    # Filter by included ingredients\n    for ing in prefs.get(\"ingredients\", []):\n        filtered = filtered[filtered['NER'].str.contains(ing, case=False, na=False)]\n\n    # Exclude disliked ingredients\n    for dislike in prefs.get(\"dislikes\", []):\n        filtered = filtered[~filtered['NER'].str.contains(dislike, case=False, na=False)]\n\n    # Limit to top 100 results\n    filtered = filtered.head(100)\n\n    # Check if anything remains\n    if filtered.empty:\n        print(\"âš ï¸ No matching recipes found in local data.\")\n        return None\n\n    # Recreate collection with filtered recipes\n    embed_fn.document_mode = True  # switch to document embedding\n    collection = create_recipe_collection(name=\"recipes\", embedding_fn=embed_fn)\n\n    documents = filtered['full_text'].tolist()\n    metadatas = filtered[['title', 'ingredients', 'directions']].to_dict(orient='records')\n    ids = [str(i) for i in filtered.index]\n\n    # Only add if all lists are non-empty\n    if documents and metadatas and ids:\n        collection.add(\n            documents=documents,\n            metadatas=metadatas,\n            ids=ids\n        )\n        return filtered\n    else:\n        print(\"âš ï¸ Filtered dataset is empty after processing. Skipping ChromaDB embedding.\")\n        return None\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:27:13.055476Z","iopub.execute_input":"2025-04-20T11:27:13.055783Z","iopub.status.idle":"2025-04-20T11:27:13.064906Z","shell.execute_reply.started":"2025-04-20T11:27:13.055762Z","shell.execute_reply":"2025-04-20T11:27:13.063644Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Look for a suitable recipe\nQuery the dataset for suitable recipes based on the user preferences","metadata":{}},{"cell_type":"code","source":"# ----------------------------\n# âœ… RAG Query Function\n# ----------------------------\ndef find_best_recipe(prefs: Dict) -> Dict:\n    \"\"\"\"\"\"\n    query_parts = prefs.get(\"ingredients\", [])\n    if prefs.get(\"dish\"):\n        query_parts.append(prefs[\"dish\"])\n    query = \" \".join(query_parts)\n\n    embed_fn.document_mode = False  # switch to query embedding\n    results = collection.query(query_texts=[query], n_results=1)\n\n    if results['documents']:\n        doc = results['metadatas'][0][0]\n        doc['full_text'] = results['documents'][0][0]\n        return doc\n    return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:27:16.112200Z","iopub.execute_input":"2025-04-20T11:27:16.112520Z","iopub.status.idle":"2025-04-20T11:27:16.118862Z","shell.execute_reply.started":"2025-04-20T11:27:16.112498Z","shell.execute_reply":"2025-04-20T11:27:16.117862Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Google Search Grounding with Gemini\nResort to using Google Search for recipes where\n1. the user wants to Google for a recipe or\n2. a recipe isn't available in the dataset","metadata":{}},{"cell_type":"code","source":"config_with_search = types.GenerateContentConfig(\n    tools=[types.Tool(google_search=types.GoogleSearch())],\n)\n\n# ----------------------------\n# ğŸ” Google Dish Suggestions via Gemini\n# ----------------------------\n\n# ğŸ” Dish name suggestion from grounded search\ndef get_dishes_from_google(prefs: Dict) -> List[str]:\n    \"\"\"Get options for dishes the user can make based on preferences where ingredients aren't given\"\"\"\n    prompt = f\"\"\"\n    Based on the following preferences, suggest 5 popular real-world dish names:\n    - Cuisine: {prefs.get('cuisine', 'any')}\n    - Diet: {prefs.get('diet', 'any')}\n    - Difficulty: {prefs.get('difficulty', 'any')}\n    - Dish Type: {prefs.get('dish', 'any')}\n\n    Return only a Python-style list of strings. No explanation.\n    Example: [\"Chocolate Cake\", \"Chocolate Chip Cookies\", \"Double Chocolate Brownies\", \"Cinnamon Rolls\", \"Nutella Cookies\"]\n    \"\"\"\n\n    response = client.models.generate_content(\n        model=\"gemini-2.0-flash\",\n        contents=prompt,\n        config=config_with_search\n    )\n\n    try:\n        text = response.candidates[0].content.parts[0].text.strip()\n        if text.startswith(\"```\") and \"python\" in text:\n            text = text.split(\"```\")[1].replace(\"python\", \"\").strip()\n        dishes = eval(text)\n        return dishes if isinstance(dishes, list) else []\n    except Exception as e:\n        print(\"âŒ Failed to parse dish suggestions:\", e)\n        return []\n\n\n# ğŸŒ Fallback: grounded recipe search\ndef grounded_google_search(dish: str, prefs: Dict = None) -> str:\n    \"\"\"Google search for a specific recipe\"\"\"\n    context = f\"authentic recipe for {dish}, include ingredients and step-by-step instructions.\"\n    if prefs:\n        if prefs.get(\"cuisine\"):\n            context += f\" Cuisine: {prefs['cuisine']}.\"\n        if prefs.get(\"diet\"):\n            context += f\" Diet: {prefs['diet']}.\"\n    response = client.models.generate_content(\n        model=\"gemini-2.0-flash\",\n        contents=context,\n        config=config_with_search\n    )\n    return response.text.strip()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:27:18.249461Z","iopub.execute_input":"2025-04-20T11:27:18.249810Z","iopub.status.idle":"2025-04-20T11:27:18.259873Z","shell.execute_reply.started":"2025-04-20T11:27:18.249775Z","shell.execute_reply":"2025-04-20T11:27:18.258798Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Compare ingredients\nFor instances where a user provides which ingredients they have, compare the ingredients to the ones in the suggested recipe and state them in the output.","metadata":{}},{"cell_type":"code","source":"# ----------------------------\n# ğŸ”§ Ingredient Diff Checker\n# ----------------------------\ndef get_missing_ingredients(recipe_ingredients, user_ingredients):\n    \"\"\"Compare user's ingredients to the recipe and return what's missing.\"\"\"\n    lower_user_ings = [i.lower() for i in user_ingredients]\n    recipe_ings = [i.lower() for i in recipe_ingredients]  # no split needed\n\n    return [i for i in recipe_ings if not any(u in i for u in lower_user_ings)]\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:27:23.427061Z","iopub.execute_input":"2025-04-20T11:27:23.427337Z","iopub.status.idle":"2025-04-20T11:27:23.433237Z","shell.execute_reply.started":"2025-04-20T11:27:23.427317Z","shell.execute_reply":"2025-04-20T11:27:23.432444Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Edit user preferences\nAdd in additional preferences if provided by user.","metadata":{}},{"cell_type":"code","source":"def merge_preferences(old: dict, new: dict) -> dict:\n    \"\"\"combine previous and new preferences specified by the user\"\"\"\n    return {\n        \"ingredients\": list(set(old.get(\"ingredients\", []) + new.get(\"ingredients\", []))),\n        \"dislikes\": list(set(old.get(\"dislikes\", []) + new.get(\"dislikes\", []))),\n        \"cuisine\": new.get(\"cuisine\") or old.get(\"cuisine\"),\n        \"diet\": new.get(\"diet\") or old.get(\"diet\"),\n        \"difficulty\": new.get(\"difficulty\") or old.get(\"difficulty\"),\n        \"dish\": new.get(\"dish\") or old.get(\"dish\"),\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:27:26.141175Z","iopub.execute_input":"2025-04-20T11:27:26.141986Z","iopub.status.idle":"2025-04-20T11:27:26.147440Z","shell.execute_reply.started":"2025-04-20T11:27:26.141937Z","shell.execute_reply":"2025-04-20T11:27:26.146534Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Update output\nThe following functions are to edit the output and have it look more cohesive.","metadata":{}},{"cell_type":"code","source":"def safe_parse_list(val):\n    if isinstance(val, list):\n        return val\n    if isinstance(val, str):\n        try:\n            return ast.literal_eval(val)\n        except:\n            return [val]\n    return [val]\n\ndef render_recipe(recipe, user_ingredients=None):\n    title = recipe.get('title', 'Untitled Recipe')\n    ingredients = safe_parse_list(recipe.get('ingredients', []))\n    directions = safe_parse_list(recipe.get('directions', []))\n\n    print(\"\\nğŸ‘©â€ğŸ³ ğŸ½ï¸ Here's a recipe you might like:\\n\")\n    print(f\"ğŸ”¸ {title.upper()}\\n\")\n\n    print(\"ğŸ§¾ INGREDIENTS:\")\n    for item in ingredients:\n        if isinstance(item, str):\n            print(f\"  - {item.strip()}\")\n\n    print(\"\\nğŸ“– INSTRUCTIONS:\")\n    for i, step in enumerate(directions, 1):\n        if isinstance(step, str):\n            print(f\"  {i}. {step.strip()}\")\n\n    if user_ingredients and len(user_ingredients) > 0:\n        missing = get_missing_ingredients(ingredients, user_ingredients)\n        if missing:\n            print(\"\\nâš ï¸ YOU MAY NOT HAVE:\")\n            for item in missing:\n                print(f\"  - {item.strip()}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T11:27:27.866634Z","iopub.execute_input":"2025-04-20T11:27:27.867074Z","iopub.status.idle":"2025-04-20T11:27:27.874774Z","shell.execute_reply.started":"2025-04-20T11:27:27.867049Z","shell.execute_reply":"2025-04-20T11:27:27.873993Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Chat between the Kitchen Assistant\nMain piece of code where the conversation takes place.","metadata":{}},{"cell_type":"code","source":"# ----------------------------\n# ğŸ¤– Chat Loop\n# ----------------------------\n\nprefs = {\n    \"ingredients\": [],\n    \"dislikes\": [],\n    \"cuisine\": \"\",\n    \"diet\": \"\",\n    \"difficulty\": \"\",\n    \"dish\": \"\"\n}\n\nprint(\"ğŸ‘©â€ğŸ³ Welcome to your AI Kitchen Assistant!\")\nprint(\"ğŸ‘©â€ğŸ³ You can tell me what you want to cook, your ingredients, any dislikes, or preferred cuisine.\")\nprint(\"ğŸ‘©â€ğŸ³ For example: 'I want to make something vegetarian without mushrooms' or 'I have chicken and rice, give me something easy'.\")\n\nwhile True:\n    user_input = input(\"ğŸ‘¤ You: \")\n    if user_input.lower() in ['exit', 'quit', 'stop', 'bye']:\n        print(\"ğŸ‘©â€ğŸ³ ğŸ‘‹ Bye! Come back anytime.\")\n        break\n\n    try:\n        new_prefs = extract_preferences(user_input)\n        prefs = merge_preferences(prefs, new_prefs)\n        print(\"ğŸ‘©â€ğŸ³ ğŸ“‹ Extracted preferences:\", prefs)\n    except Exception as e:\n        print(\"ğŸ‘©â€ğŸ³ âŒ Couldn't extract preferences. Try again.\")\n        continue\n\n    # Case 1: High-level preferences (no ingredients)\n    if not prefs.get(\"ingredients\") and (prefs.get(\"cuisine\") or prefs.get(\"diet\") or prefs.get(\"difficulty\")):\n        dishes = get_dishes_from_google(prefs)\n        if not dishes:\n            print(\"ğŸ‘©â€ğŸ³ ğŸ¤– Couldn't suggest dishes. Could you try rephrasing?\")\n            continue\n\n        print(\"ğŸ‘©â€ğŸ³ ğŸ¤– Here are some dishes you might like:\")\n        for i, dish in enumerate(dishes, 1):\n            print(f\"{i}. {dish}\")\n\n        selected = input(\"\\nğŸ‘©â€ğŸ³ Which one would you like to make? \").strip()\n        print(\"\\nğŸ‘©â€ğŸ³ ğŸ” Searching for the recipe...\\n\")\n        recipe_text = grounded_google_search(selected, prefs)\n        display(Markdown(recipe_text))\n\n        user_feedback = input(\"\\nğŸ‘©â€ğŸ³ Is this the kind of recipe you had in mind? (yes/no/stop): \").strip().lower()\n        if user_feedback in ['yes', 'stop']:\n            print(\"ğŸ‘©â€ğŸ³ ğŸ‰ Enjoy your meal!\" if user_feedback == 'yes' else \"ğŸ‘©â€ğŸ³ ğŸ‘‹ Okay, see you next time!\")\n            break\n        else:\n            print(\"ğŸ‘©â€ğŸ³ ğŸ¤” Okay, let's try again.\")\n            continue\n\n    # Case 2: Ingredients-based search\n    filtered = filter_and_embed_recipes(prefs, df)\n\n    if filtered is None or filtered.empty:\n        print(\"ğŸ‘©â€ğŸ³ ğŸ˜• Couldn't find a good recipe locally. Searching Google...\")\n        display(Markdown(grounded_google_search(user_input)))\n        break\n\n    recipe = find_best_recipe(prefs)\n\n    if recipe:\n        render_recipe(recipe, prefs.get('ingredients'))\n\n        user_feedback = input(\"\\nğŸ‘©â€ğŸ³ Are you happy with this recipe? (yes/no/google/stop): \").strip().lower()\n        if user_feedback == 'yes':\n            print(\"ğŸ‘©â€ğŸ³ ğŸ‰ Enjoy your meal!\")\n            break\n        elif user_feedback == 'google':\n            print(\"\\nğŸ‘©â€ğŸ³ ğŸ” Searching Google...\")\n            display(Markdown(grounded_google_search(user_input)))\n            break\n        elif user_feedback == 'stop':\n            print(\"ğŸ‘©â€ğŸ³ ğŸ‘‹ Okay, see you next time!\")\n            break\n        else:\n            print(\"ğŸ‘©â€ğŸ³ ğŸ¤” Okay, let's try again.\")\n    else:\n        print(\"ğŸ‘©â€ğŸ³ ğŸ˜• Couldn't find a suitable recipe. Let's try Google.\")\n        display(Markdown(grounded_google_search(user_input)))\n        break\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-20T12:15:30.413518Z","iopub.execute_input":"2025-04-20T12:15:30.414007Z","iopub.status.idle":"2025-04-20T12:15:54.151624Z","shell.execute_reply.started":"2025-04-20T12:15:30.413971Z","shell.execute_reply":"2025-04-20T12:15:54.150410Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}